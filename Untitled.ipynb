{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6e9e5-a13b-4ebe-a867-6d7b219676cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n",
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\tunet_output_sup0_activation\n",
      "\tunet_output_sup1_activation\n",
      "\tunet_output_final_activation\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Read in packages\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "import os\n",
    "import segmentation_models as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import concatenate, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Input, AvgPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_unet_collection import models\n",
    "import tensorflow_addons as tfa\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#minimum and maximum values to apply same normalization during draining\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/modis_glob_norm.csv\").reset_index(drop = True)\n",
    "\n",
    "#6, 7, 8 correspond to dNBR, dNDVI, dNDII, if you change these bands this must change. .\n",
    "min_max = min_max[['7', '8', '9']]\n",
    "\n",
    "\n",
    "#function to get files from storage bucket\n",
    "def get_files(bucket_path):\n",
    "\n",
    "\t\"\"\"argument is the path to where the numpy\n",
    "\tsave files are located, return a list of filenames\n",
    "\t\"\"\"\n",
    "\tall = []\n",
    "\n",
    "\t#list of files\n",
    "\tfiles = os.listdir(bucket_path)\n",
    "\n",
    "\t#get list of filenames we will use, notte I remove images that don't have a target due to clouds\n",
    "\tfile_names = []\n",
    "\tfor f in files:\n",
    "\n",
    "\t\tif f.endswith('.npy'):\n",
    "\n",
    "\n",
    "\t\t\tall.append(os.path.join(bucket_path, f))\n",
    "\treturn(all)\n",
    "\n",
    "\n",
    "#get all the pathways for mtbs., 128x128 chunks\n",
    "training_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/modis_nbac_16_training_files.csv')['Files'].tolist()\n",
    "validation_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/modis_nbac_16_validation_files.csv')['Files'].tolist()\n",
    "testing_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/modis_nbac_16_testing_files.csv')['Files'].tolist()\n",
    "\n",
    "#get all pathways to nbac\n",
    "training_names2 = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/modis_mtbs_16_training_files.csv')['Files'].tolist()\n",
    "validation_names2 = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/modis_mtbs_16_validation_files.csv')['Files'].tolist()\n",
    "testing_names2 = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/modis_mtbs_16_testing_files.csv')['Files'].tolist()\n",
    "\n",
    "#combine\n",
    "training_names = training_names + training_names2 \n",
    "validation_names = validation_names + validation_names2\n",
    "testing_names = testing_names + testing_names2\n",
    "\n",
    "#scale 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "#image generator for 3 bands, some pre processing here to turn nan to 0, ensure the min-max values are used for normalization.  \n",
    "#the numpy arrays have bands red, green, blue, nir, swir1, swir2, dNBR, dNDVI, dNDII, y. \n",
    "class img_gen(tensorflow.keras.utils.Sequence):\n",
    "\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\n",
    "    Inputs are batch size, the image size, the input paths (x) and target paths (y)\n",
    "    \"\"\"\n",
    "\n",
    "    #will need pre defined variables batch_size, img_size, input_img_paths and target_img_paths\n",
    "    def __init__(self, batch_size, img_size, input_img_paths):\n",
    "\t    self.batch_size = batch_size\n",
    "\t    self.img_size = img_size\n",
    "\t    self.input_img_paths = input_img_paths\n",
    "\t    self.target_img_paths = input_img_paths\n",
    "\n",
    "    #number of batches the generator is supposed to produceis the length of the paths divided by the batch siize\n",
    "    def __len__(self):\n",
    "\t    return len(self.input_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_img_paths = self.input_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (x)\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (y)\n",
    "\t\t\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\") #create matrix of zeros which will have the dimension height, wideth, n_bands), 8 is the n_bands\n",
    "        \n",
    "  \n",
    "         #start populating x by enumerating over the input img paths\n",
    "        for j, path in enumerate(batch_img_paths):\n",
    "\n",
    "            #load image\n",
    "            img =  np.round(np.load(path), 3)[:, :, 7:10]\n",
    "\n",
    "            # img = img * 1000\n",
    "            img = img.astype(float)\n",
    "            img = np.round(img, 3)\n",
    "            img[img == 0] = -999\n",
    "\n",
    "            img[np.isnan(img)] = -999\n",
    "\n",
    "\n",
    "            img[img == -999] = np.nan\n",
    "\n",
    "            in_shape = img.shape\n",
    "            \n",
    "            #turn to dataframe to normalize\n",
    "            img = img.reshape(img.shape[0] * img.shape[1], img.shape[2])\n",
    "\t\t\t\n",
    "            img = pd.DataFrame(img)\n",
    "\t\t\t\n",
    "            img.columns = min_max.columns\n",
    "\t\t\t\n",
    "            img = pd.concat([min_max, img]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "            #normalize 0 to 1\n",
    "            img = pd.DataFrame(scaler.fit_transform(img))\n",
    "\t\t\t\n",
    "            img = img.iloc[2:]\n",
    "#\n",
    "#             img = img.values.reshape(in_shape)\n",
    "            img = img.values.reshape(in_shape)\n",
    "\n",
    "#             replace nan with -1\n",
    "            img[np.isnan(img)] = -1\n",
    "\n",
    "#apply standardization\n",
    "# img = normalize(img, axis=(0,1))\n",
    "\n",
    "            img = np.round(img, 3)\n",
    "            #populate x\n",
    "            x[j] = img#[:, :, 4:] index number is not included, \n",
    "\n",
    "\n",
    "        #do tthe same thing for y\n",
    "        y = np.zeros((self.batch_size,) + self.img_size, dtype=\"uint8\")\n",
    "\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "\n",
    "            #load image\n",
    "            img =  np.round(np.load(path), 3)[:, :, -1]\n",
    "\n",
    "            img = img.astype(int)\n",
    "\n",
    "            img[img < 0] = 0\n",
    "            img[img >1] = 0\n",
    "            img[~np.isin(img, [0,1])] = 0\n",
    "\n",
    "            img[np.isnan(img)] = 0\n",
    "            img = img.astype(int)\n",
    "\n",
    "            y[j] = img\n",
    "  \n",
    "       \n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#batch size and img size\n",
    "BATCH_SIZE = 45\n",
    "GPUS = [\"GPU:0\", \"GPU:1\", \"GPU:2\", \"GPU:3\"]\n",
    "strategy = tensorflow.distribute.MirroredStrategy() #can add GPUS here to select specific ones\n",
    "print('Number of devices: %d' % strategy.num_replicas_in_sync) \n",
    "\n",
    "batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "#image size\n",
    "img_size = (16, 16)\n",
    "\n",
    "#number of classes to predict\n",
    "num_classes = 1\n",
    "\n",
    "#get images\n",
    "train_gen = img_gen(batch_size, img_size, training_names)\n",
    "val_gen = img_gen(batch_size, img_size, validation_names)\n",
    "test_gen = img_gen(batch_size, img_size, testing_names)\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "tensorflow.keras.backend.clear_session()\n",
    "\n",
    "#set learning rate\n",
    "LR = 1e-3\n",
    "\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=LR) #this is 1e-3, default or 'rmsprop'\n",
    "    \n",
    "#callbacks to save only best model, what to monitor for early stopping and reduce learning rate etc. \n",
    "callbacks = [tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/models/nbac_mtbs_modis_16_global_norm\",\n",
    "#     verbose=1,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    monitor='val_unet_output_final_activation_iou_score',\n",
    "    mode = 'max'),\n",
    "    tensorflow.keras.callbacks.EarlyStopping(monitor='val_unet_output_final_activation_iou_score', mode = 'max',  patience=20),\n",
    "    tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_unet_output_final_activation_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)]\n",
    "\n",
    "#training loop\n",
    "# Open a strategy scope, to use multiple gpus\n",
    "with strategy.scope():\n",
    "\n",
    "    model_unet_from_scratch = models.unet_plus_2d((None, None, 3), filter_num= [16,32,64,128], #make smaller64, 128, 256, 512,[16, 32, 64, 128]\n",
    "                       n_labels=num_classes, \n",
    "                       stack_num_down=2, stack_num_up=2, \n",
    "                       activation='ReLU', \n",
    "                       output_activation='Sigmoid', \n",
    "                       batch_norm=True, pool=False, unpool=False, \n",
    "                       backbone='EfficientNetB7', weights=None, \n",
    "                       freeze_backbone=False, freeze_batch_norm=False, \n",
    "                       deep_supervision = True,\n",
    "                       name='unet')\n",
    "\n",
    "    model_unet_from_scratch.compile(loss='binary_crossentropy',\n",
    "                                    optimizer='adam',\n",
    "                                    metrics=[sm.metrics.Precision(threshold=0.5),\n",
    "                                      sm.metrics.Recall(threshold=0.5),\n",
    "                                      sm.metrics.FScore(threshold=0.5), \n",
    "                                      sm.metrics.IOUScore(threshold=0.5),\n",
    "                                      'accuracy'])\n",
    "\n",
    "#fit the model\n",
    "history = model_unet_from_scratch.fit(\n",
    "    train_gen,\n",
    "    epochs=100,\n",
    "    callbacks = callbacks,\n",
    "    validation_data=val_gen,\n",
    "    verbose = 0) \n",
    "\n",
    "#save final model\n",
    "model_unet_from_scratch.save(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/models/nbac_mtbs_modis_16_global_norm.tf\")\n",
    "\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "#training/val results\n",
    "result = pd.DataFrame({'Precision': history_dict[\"unet_output_final_activation_precision\"],\n",
    "                       'Val_Precision': history_dict['val_unet_output_final_activation_precision'],\n",
    "                       'Recall': history_dict[\"unet_output_final_activation_recall\"],\n",
    "                       'Val_Recall': history_dict['val_unet_output_final_activation_recall'],\n",
    "                       'F1': history_dict[\"unet_output_final_activation_f1-score\"],\n",
    "                       'Val_F1': history_dict['val_unet_output_final_activation_f1-score'],\n",
    "                       'IOU': history_dict[\"unet_output_final_activation_iou_score\"],\n",
    "                       'Val_IOU': history_dict['val_unet_output_final_activation_iou_score'],\n",
    "                       'Loss': history_dict['unet_output_final_activation_loss'],\n",
    "                       'Val_Loss': history_dict['val_unet_output_final_activation_loss'],\n",
    "                      'Accuracy': history_dict['unet_output_final_activation_accuracy'],\n",
    "                       'Val_Accuracy': history_dict['val_unet_output_final_activation_accuracy']})\n",
    "\n",
    "#save to csv\n",
    "result.to_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_mtbs_modis_16_global_norm.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the time difference in seconds\n",
    "time_difference_seconds = end_time - start_time\n",
    "\n",
    "# Convert seconds to hours\n",
    "time_difference_hours = time_difference_seconds / 3600  # 1 hour = 3600 seconds\n",
    "\n",
    "print(f\"Time taken: {time_difference_hours:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240050d-2e95-405d-ab00-9aa69ea490fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1522a1-ce78-47be-9d86-746924617343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning3]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
