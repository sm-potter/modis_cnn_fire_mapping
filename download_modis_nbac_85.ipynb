{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e7072d-2a59-4e77-8355-0e91c9806a36",
   "metadata": {},
   "source": [
    "Read in all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acaa055-2958-4387-b53d-5afa0a7a6e0d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "from geeml.extract import extractor\n",
    "from google.cloud import storage\n",
    "from google.cloud import client\n",
    "import random\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "\n",
    "service_account = 'gee-serdp-upload@appspot.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "ee.Initialize(credentials)\n",
    "# Initialize GEE with high-volume end-point\n",
    "# ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a394c13c-8cd8-4cbe-9515-6759f836b6bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "storage_client = storage.Client.from_service_account_json(\"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "storage_client = storage.Client()\n",
    "# bucket_name = 'smp-scratch/mtbs_1985'\n",
    "bucket_name = 'smp-scratch'\n",
    "\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4eb4aa-2c2c-489e-8d91-707fb86fb3ff",
   "metadata": {},
   "source": [
    "Read in the feature collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6155d1-080a-4a4b-87eb-3effac67db6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dem = ee.Image(\"UMN/PGC/ArcticDEM/V3/2m_mosaic\") #arctic dem\n",
    "sent_2A = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "ak = ee.FeatureCollection(\"users/spotter/alaska\") #ak shapefile\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_lfdb_1985\") #ak fire polygons\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_lfdb_2014\") #ak fire polygons\n",
    "lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_1985\") #ak fire polygons\n",
    "\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_2013\") #ak fire polygons\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_mtbs_2014\")\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_mtbs_1985\")\n",
    "\n",
    "water = ee.ImageCollection(\"JRC/GSW1_3/YearlyHistory\") #water mask\n",
    "\n",
    "#since we are using modis can only use fires from 2001 and onward\n",
    "lfdb = lfdb.filter(ee.Filter.gte('Year', 2001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54194e75-f36d-49a1-8c4e-4708cf26a295",
   "metadata": {},
   "source": [
    "MODIS collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99d8a6a-9ab9-487b-b18a-864724c66e53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "terra = ee.ImageCollection(\"MODIS/061/MOD09A1\")\n",
    "aqua = ee.ImageCollection(\"MODIS/061/MYD09A1\")\n",
    "\n",
    "modis = terra.merge(aqua)\n",
    "\n",
    "#only select good quality pixels\n",
    "# def filter(image): \n",
    "#     mask = image.select('QA').neq(0)\n",
    "#     return ee.Image(image).updateMask(mask)\n",
    "\n",
    "\n",
    "def maskClouds(image):\n",
    "    # The StateQA band contains information about clouds, shadows, and more.\n",
    "    qa = image.select('StateQA')\n",
    "    \n",
    "    # Bits 0-1 indicate the pixel is clear (00), cloudy (01), mixed (10), or not set (11)\n",
    "    # Bits 2-3 indicate the pixel is a cloud shadow (01) or not\n",
    "    # Create a mask to filter out cloudy and shadow pixels.\n",
    "    cloudShadowBitMask = (1 << 2)\n",
    "    cloudsBitMask = (1 << 0)\n",
    "    \n",
    "    # Use bitwise operations to mask out clouds and shadows.\n",
    "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0) \\\n",
    "            .And(qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "    \n",
    "    # Apply the mask to the image, setting non-clear pixels to null.\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "modis = modis.map(maskClouds);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008b3d2b-a759-4d89-8181-7c08cef80ab0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_pre_post(pre_start, pre_end, post_start, post_end, geometry):\n",
    "\n",
    "    \"\"\"parameters are:\n",
    "    pre_start: the start date for pre fire imagery\n",
    "    pre_end: the end date for pre fire imagery\n",
    "    post_start: the start date for post fire imagery\n",
    "    post_end: the end date for post_fire imagery\n",
    "    geometry: the geometry to filter by\n",
    "    returns: list of images\n",
    "    \"\"\"\n",
    "\n",
    "    pre_input_collection = modis.filterDate(pre_start, pre_end).select(['sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b04', 'sur_refl_b05', 'sur_refl_b06', 'sur_refl_b07'])\n",
    "\n",
    "    pre_input = pre_input_collection.median().clip(final_buffer).multiply(1000)\n",
    "\n",
    "    #post firre\n",
    "    post_input_collection = modis.filterDate(post_start, post_end).select(['sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b04', 'sur_refl_b05', 'sur_refl_b06', 'sur_refl_b07'])\n",
    "\n",
    "\n",
    "    post_input = post_input_collection.median().clip(final_buffer).multiply(1000)\n",
    "    \n",
    "    return pre_input, post_input\n",
    "\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfc02a-cccd-40aa-bcee-0f3dfb8567e5",
   "metadata": {},
   "source": [
    "Loop through and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647c4bf-f065-43bc-afda-3d9b731cd333",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading median_4628.tif\n",
      "Downloading median_6169.tif\n",
      "Downloading median_10045.tif\n",
      "Downloading median_10849.tif\n",
      "Downloading median_11241.tif\n",
      "Downloading median_11146.tif\n",
      "Downloading median_3606.tif\n",
      "Downloading median_3635.tif\n",
      "Downloading median_3645.tif\n",
      "Downloading median_3685.tif\n",
      "Downloading median_3703.tif\n",
      "Downloading median_4541.tif\n",
      "Downloading median_4721.tif\n",
      "Downloading median_4490.tif\n",
      "Downloading median_4568.tif\n",
      "Downloading median_4573.tif\n",
      "Downloading median_4480.tif\n"
     ]
    }
   ],
   "source": [
    "all_dates = ee.List(lfdb.distinct([\"ID\"]).aggregate_array(\"ID\"))\n",
    "all_dates = all_dates.getInfo()\n",
    "\n",
    "\n",
    "pre_months = ['-04-01', '-05-01', '-06-01', '-07-01', '-08-01', '-09-01', '-06-01']\n",
    "end_months = ['-05-01', '-06-01', '-07-01', '-08-01', '-09-01', '-10-01', '-08-31']\n",
    "\n",
    "all_months = dict(zip(pre_months, end_months))\n",
    "\n",
    "\n",
    "for i in all_dates:\n",
    "\n",
    "  # print(id)\n",
    "  # if id not in [1909, 1066, 1716]:\n",
    "  # if id in [3823]:\n",
    "\n",
    "    # try:\n",
    "    # print(raw_bands.toFloat().getInfo())\n",
    "    fname = f\"median_{i}.tif\"\n",
    "\n",
    "    # if os.path.isfile(os.path.join('gs://smp-scratch/test_cnn', fname)) == False:\n",
    "\n",
    "    # name = os.path.join('gs://smp-scratch', fname)\n",
    "    name = fname\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    # bucket_name = 'smp-scratch/mtbs_1985'\n",
    "    bucket_name = 'smp-scratch'\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    stats = storage.Blob(bucket=bucket, name=name).exists(storage_client)\n",
    "\n",
    "    if stats == False:\n",
    "\n",
    "        #get the fire polygon of interest\n",
    "        sub_shape = lfdb.filter(ee.Filter.eq(\"ID\", i))\n",
    "\n",
    "        #get all other fire ids that are not this one\n",
    "        not_fires = lfdb.filter(ee.Filter.neq(\"ID\", i))\n",
    "\n",
    "\n",
    "        #first get the bounding box of the fire\n",
    "        bbox = sub_shape.geometry().bounds()\n",
    "\n",
    "\n",
    "        #offset the bounding box by a random number\n",
    "        # all_rands = [0.00, 0.02, -0.02]\n",
    "        all_rands = [0.00]\n",
    "\n",
    "\n",
    "        rand1 = random.sample(all_rands, 1)[0]\n",
    "        rand2 = random.sample(all_rands, 1)[0]\n",
    "\n",
    "        #offset applied\n",
    "        proj = ee.Projection(\"EPSG:4326\").translate(rand1, rand2)\n",
    "\n",
    "        #for the bounding box apply the randomly selected offset\n",
    "        final_buffer = ee.Geometry.Polygon(bbox.coordinates(), proj).transform(proj)\n",
    "\n",
    "        #this is a bit of a hack but we have two different bounding box sizes because when we export we need to use some additonal area to avoid cuttoffs\n",
    "#         final_buffer2 = final_buffer.buffer(distance= 5000).bounds()\n",
    "\n",
    "#         final_buffer = final_buffer.buffer(distance= 40000)#.bounds().transform(proj='EPSG:3413', maxError=1)\n",
    "\n",
    "        final_buffer2 = final_buffer.buffer(distance= (5000)).bounds()\n",
    "\n",
    "        final_buffer = final_buffer.buffer(distance= (40000))#.bounds().transform(proj='EPSG:3413', maxError=1)\n",
    "\n",
    "     #get the year of this fire\n",
    "        this_year = ee.Number(sub_shape.aggregate_array('Year').get(0))\n",
    "        \n",
    "        year = this_year.getInfo() \n",
    "        \n",
    "        pre_start = ee.Date.fromYMD(this_year.subtract(1), 6, 1)\n",
    "        pre_end = ee.Date.fromYMD(this_year.subtract(1), 8, 31)\n",
    "        post_start = pre_start.advance(2, 'year')\n",
    "        post_end = pre_end.advance(2, 'year')\n",
    "     \n",
    "        #just getting some date info here to ensure pre fire is one  year before and post fire is one year after the fire year of interest\n",
    "        startYear = pre_start.get('year')\n",
    "\n",
    "        #convert to client side\n",
    "        startYear = startYear.getInfo()  # local string\n",
    "        endYear = str(int(startYear) + 2)\n",
    "        startYear = str(startYear)\n",
    "        \n",
    "        #loop through all the months and use 85th percentile to download all data\n",
    "        all_months_images = []\n",
    "\n",
    "         #loop through all months \n",
    "        for m1, m2 in all_months.items():\n",
    "\n",
    "            if m1 == '-06-01' and m2 == '-08-31':\n",
    "\n",
    "                start_year = year - 1\n",
    "                end_year = year + 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                start_year = year - 1\n",
    "                end_year = year\n",
    "\n",
    "\n",
    "\n",
    "            #get pre dates\n",
    "            pre_start = str(start_year) + m1\n",
    "            pre_end = str(start_year) + m2\n",
    "\n",
    "            #get post dates\n",
    "\n",
    "\n",
    "            post_start = str(end_year) + m1\n",
    "            post_end = str(end_year) + m2\n",
    "\n",
    "        \n",
    "             #apply the function to get the pre_fire image and post_fire image\n",
    "            all_imagery = get_pre_post(pre_start, pre_end, post_start, post_end, final_buffer)\n",
    "\n",
    "            #return the pre and post fire input imagery lists\n",
    "            pre_input = all_imagery[0]\n",
    "            post_input = all_imagery[1]\n",
    "            \n",
    "              # print(post_input.getInfo())\n",
    "            #get pre and post NDVI, ndvi and ndii\n",
    "            preNBR = pre_input.normalizedDifference(['sur_refl_b02', 'sur_refl_b07']).select([0], ['preNBR'])\n",
    "\n",
    "\n",
    "            postNBR = post_input.normalizedDifference(['sur_refl_b02', 'sur_refl_b07']).select([0], ['postNBR'])\n",
    "\n",
    "            #get dNDVI\n",
    "            dNBR = preNBR.select('preNBR').subtract(postNBR.select('postNBR'))\n",
    "            dNBR = dNBR.select('preNBR').rename('dNBR').multiply(1000) #don't need to scale for normalized difference, it goes -1 to 1 anyway\n",
    "\n",
    "\n",
    "            #-----NDVI\n",
    "            preNDVI = pre_input.normalizedDifference(['sur_refl_b02', 'sur_refl_b01']).select([0], ['preNDVI'])\n",
    "\n",
    "\n",
    "            postNDVI = post_input.normalizedDifference(['sur_refl_b02', 'sur_refl_b01']).select([0], ['postNDVI'])\n",
    "\n",
    "            #get dNDVI\n",
    "            NDVI = preNDVI.select('preNDVI').subtract(postNDVI.select('postNDVI'))\n",
    "            NDVI = NDVI.select('preNDVI').rename('NDVI').multiply(1000)\n",
    "\n",
    "\n",
    "            #-----NDII\n",
    "            preNDII = pre_input.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).select([0], ['preNDII'])\n",
    "\n",
    "\n",
    "            postNDII = post_input.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).select([0], ['postNDII'])\n",
    "\n",
    "            #get dNDVI\n",
    "            NDII = preNDII.select('preNDII').subtract(postNDII.select('postNDII'))\n",
    "            NDII = NDII.select('preNDII').rename('NDII').multiply(1000)\n",
    "\n",
    "            #difference the raw bands\n",
    "            diff = pre_input.subtract(post_input)\n",
    "\n",
    "            #combine\n",
    "\n",
    "            raw_bands = diff.addBands(dNBR).addBands(NDVI).addBands(NDII)\n",
    "\n",
    "            b1 = raw_bands.select('sur_refl_b01').cast({'sur_refl_b01':'short'})\n",
    "            b2 = raw_bands.select('sur_refl_b02').cast({'sur_refl_b02':'short'})\n",
    "            b3 = raw_bands.select('sur_refl_b03').cast({'sur_refl_b03':'short'})\n",
    "            b4 = raw_bands.select('sur_refl_b04').cast({'sur_refl_b04':'short'})\n",
    "            b5 = raw_bands.select('sur_refl_b05').cast({'sur_refl_b05':'short'})\n",
    "            b6 = raw_bands.select('sur_refl_b06').cast({'sur_refl_b06':'short'})\n",
    "            b7 = raw_bands.select('sur_refl_b07').cast({'sur_refl_b07':'short'})\n",
    "\n",
    "            b8 = raw_bands.select('dNBR').cast({'dNBR':'short'})\n",
    "            b9 = raw_bands.select('NDVI').cast({'NDVI':'short'})\n",
    "            b10 = raw_bands.select('NDII').cast({'NDII':'short'})\n",
    "\n",
    "            raw_bands = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6).addBands(b7).addBands(b8).addBands(b9).addBands(b10)\n",
    "            \n",
    "            all_months_images.append(raw_bands)\n",
    "                \n",
    "        #append to all_days vi\n",
    "        raw_bands = ee.ImageCollection(all_months_images).reduce(ee.Reducer.percentile([85]))\n",
    "        \n",
    "        b1 = raw_bands.select('sur_refl_b1_p85').cast({'sur_refl_b1_p85':'short'}) #0\n",
    "        b2 = raw_bands.select('sur_refl_b2_p85').cast({'sur_refl_b2_p85':'short'}) #1\n",
    "        b3 = raw_bands.select('sur_refl_b3_p85').cast({'sur_refl_b3_p85':'short'}) #2\n",
    "        b4 = raw_bands.select('sur_refl_b4_p85').cast({'sur_refl_b4_p85':'short'}) #3\n",
    "        b5 = raw_bands.select('sur_refl_b5_p85').cast({'sur_refl_b5_p85':'short'}) #4\n",
    "        b6 = raw_bands.select('sur_refl_b6_p85').cast({'sur_refl_b6_p85':'short'}) #5\n",
    "        b7 = raw_bands.select('sur_refl_b6_p85').cast({'sur_refl_b6_p85':'short'}) #5\n",
    "        b8 = raw_bands.select('dNBR_p85').cast({'dNBR_p85':'short'}) #band 6 is dnbr is numpy\n",
    "        b9 = raw_bands.select('NDVI_p85').cast({'NDVI_p85':'short'}) #7\n",
    "        b10 = raw_bands.select('NDII_p85').cast({'NDII_p85':'short'}) #8\n",
    "        \n",
    "        \n",
    "        raw_bands = raw_bands.clip(final_buffer)\n",
    "        \n",
    "        #we need to see which image ids from the entire lfdb are already included in the buffer\n",
    "        lfdb_filtered_orig = lfdb.filterBounds(final_buffer)\n",
    "\n",
    "        #ensure all fires are within the actual year of interest (this_year) and two years prior, otherwise ignore, this is to ensure we don't have nearby fires from previous years\n",
    "        first_year =  int(startYear) + 1\n",
    "        second_year =  int(startYear)\n",
    "        third_year =  int(startYear) - 1\n",
    "        fourth_year = int(startYear) + 2\n",
    "\n",
    "        lfdb_filtered = lfdb_filtered_orig.filter(ee.Filter.eq(\"Year\", year))\n",
    "\n",
    "        bad_filtered = lfdb_filtered_orig.filter(ee.Filter.Or(ee.Filter.eq(\"Year\", second_year), ee.Filter.eq(\"Year\", third_year), ee.Filter.eq(\"Year\", fourth_year)))\n",
    "\n",
    " #get ids which are in image\n",
    "        all_dates_new = ee.List(lfdb_filtered.distinct([\"ID\"]).aggregate_array(\"ID\")).getInfo()\n",
    "\n",
    "\n",
    "        #remove ids from all dates which we do not need anymore\n",
    "        all_dates = [i for i in all_dates if i not in all_dates_new]\n",
    "\n",
    "        #area we have good fires\n",
    "        fire_rast = lfdb_filtered.reduceToImage(properties= ['ID'], reducer = ee.Reducer.first())\n",
    "\n",
    "        #areas we have fires from other years or nearby we don't want to use\n",
    "        bad_fire_rast = bad_filtered.reduceToImage(properties= ['ID'], reducer = ee.Reducer.first())\n",
    "\n",
    "        #change values to 1 for fire of interest\n",
    "        fire_rast = fire_rast.where(fire_rast.gt(0), 1)\n",
    "\n",
    "        #change values for bad fire raster to 1 as well\n",
    "        bad_fire_rast = bad_fire_rast.where(bad_fire_rast.gt(0), 1)\n",
    "\n",
    "        #if the fires overlap we want to keep those locations\n",
    "        bad_fire_rast = bad_fire_rast.where(bad_fire_rast.eq(1).And(fire_rast.eq(1)), 2).unmask(-999)\n",
    "\n",
    "        #rename to y for the fire raster\n",
    "        fire_rast = fire_rast.rename(['y'])\n",
    "\n",
    "        #copy the first values of raw_bands\n",
    "        y = raw_bands.select(['dNBR_p85'], ['y'])\n",
    "\n",
    "        #turn all values of y to 0\n",
    "        y  = y.where(y.gt(-10000), 0)\n",
    "\n",
    "        #turn values to 1 where fire_rast is 1\n",
    "        y  = y.where(fire_rast.eq(1), 1)\n",
    "\n",
    "        b11 = y.select('y').cast({'y':'short'})\n",
    "\n",
    "\n",
    "        #for areas where there are nearby fires or fires in previous years we set those to 0\n",
    "        raw_bands = raw_bands.updateMask(bad_fire_rast.neq(1))\n",
    "\n",
    "        #add in the target variable\n",
    "        raw_bands = raw_bands.addBands(b11)\n",
    "\n",
    "        #start download\n",
    "        print(f\"Downloading {fname}\")\n",
    "\n",
    "\n",
    "        task = ee.batch.Export.image.toCloudStorage(\n",
    "                              image = raw_bands.toShort(),\n",
    "                              region=final_buffer2, \n",
    "                              description='median_' + str(i),\n",
    "                              crs= 'SR-ORG:6974',\n",
    "                              scale = 463.3127165275,\n",
    "                              maxPixels=1e13,\n",
    "                              bucket = 'smp-scratch')\n",
    "\n",
    "        task.start()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c38bcdd-a5e0-46b7-a80f-edd5285f9559",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_bands = ee.ImageCollection(all_months_images).reduce(ee.Reducer.percentile([85]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12ae772-f241-46be-9b52-43f9cc5e5736",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'bands': [{'id': 'sur_refl_b01_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'sur_refl_b02_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'sur_refl_b03_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'sur_refl_b04_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'sur_refl_b05_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'sur_refl_b06_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'sur_refl_b07_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'dNBR_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'NDVI_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]},\n",
       "  {'id': 'NDII_p85',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'double',\n",
       "    'min': -32768,\n",
       "    'max': 32767},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [1, 0, 0, 0, 1, 0]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_bands.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f8b47-7d2a-4d72-a027-5355f9ae1a58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gee_ml]",
   "language": "python",
   "name": "conda-env-.conda-gee_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
